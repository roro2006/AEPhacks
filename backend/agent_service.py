"""
Autonomous Grid Monitor Agent Service
Implements proactive monitoring, pattern recognition, and predictive capabilities
using IEEE 738 calculations and historical analysis
"""
import os
from anthropic import Anthropic
from dotenv import load_dotenv
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field, asdict
from collections import deque
import numpy as np
from pydantic import BaseModel

# Load environment variables
load_dotenv()


class GridMetrics(BaseModel):
    """Snapshot of grid metrics at a point in time"""
    timestamp: str
    total_lines: int
    critical_count: int
    high_stress_count: int
    caution_count: int
    normal_count: int
    avg_loading: float
    max_loading: float
    max_loading_line: str
    weather_temp: float
    weather_wind_speed: float
    weather_wind_angle: float
    weather_sun_time: float


class PatternData(BaseModel):
    """Recognized pattern in grid behavior"""
    pattern_type: str  # 'weather_impact', 'loading_trend', 'issue_sequence', 'resolution'
    trigger_conditions: Dict
    observed_outcomes: List[Dict]
    confidence: float
    occurrence_count: int
    last_seen: str
    avg_severity: float


class ActionRecord(BaseModel):
    """Record of actions taken and their outcomes"""
    action_id: str
    timestamp: str
    action_type: str  # 'alert', 'recommendation', 'prediction'
    description: str
    grid_state_before: Dict
    grid_state_after: Optional[Dict] = None
    outcome: Optional[str] = None  # 'successful', 'failed', 'ignored', 'pending'
    impact_score: Optional[float] = None


class Alert(BaseModel):
    """Proactive alert generated by the agent"""
    alert_id: str
    timestamp: str
    severity: str  # 'info', 'warning', 'critical', 'emergency'
    title: str
    description: str
    affected_lines: List[str]
    recommended_actions: List[str]
    confidence: float
    pattern_match: Optional[str] = None


class Recommendation(BaseModel):
    """Prioritized recommendation from the agent"""
    rec_id: str
    timestamp: str
    priority: int  # 1-5, 1 being highest
    title: str
    description: str
    justification: str
    expected_impact: Dict
    confidence: float
    actionable_steps: List[str]


class Prediction(BaseModel):
    """Future state prediction"""
    prediction_id: str
    timestamp: str
    forecast_time: str
    predicted_metrics: Dict
    confidence: float
    risk_factors: List[str]
    preventive_actions: List[str]


@dataclass
class AgentState:
    """
    Maintains the autonomous agent's state including:
    - Historical grid conditions
    - Pattern recognition data
    - Action history
    - Current monitoring thresholds
    - Alert status
    """

    # Historical data storage (circular buffers)
    grid_history: deque = field(default_factory=lambda: deque(maxlen=1000))

    # Pattern recognition
    recognized_patterns: List[PatternData] = field(default_factory=list)

    # Action tracking
    action_history: deque = field(default_factory=lambda: deque(maxlen=500))

    # Monitoring thresholds (can be adjusted through learning)
    thresholds: Dict = field(default_factory=lambda: {
        'loading': {
            'normal': 60.0,
            'caution': 90.0,
            'high': 100.0,
            'critical': 100.0
        },
        'trend': {
            'loading_increase_rate': 5.0,  # % per hour
            'temperature_sensitivity': 0.5,  # % loading change per °C
        },
        'pattern_confidence': 0.7,  # Minimum confidence to act on pattern
        'prediction_horizon': 2.0,  # Hours ahead to predict
    })

    # Current alerts
    active_alerts: List[Alert] = field(default_factory=list)

    # Current recommendations
    active_recommendations: List[Recommendation] = field(default_factory=list)

    # Predictions
    active_predictions: List[Prediction] = field(default_factory=list)

    # Agent metadata
    agent_start_time: str = field(default_factory=lambda: datetime.now().isoformat())
    last_update: str = field(default_factory=lambda: datetime.now().isoformat())
    total_actions: int = 0
    successful_predictions: int = 0
    total_predictions: int = 0

    def to_dict(self) -> Dict:
        """Convert state to dictionary for serialization"""
        return {
            'grid_history_count': len(self.grid_history),
            'patterns_count': len(self.recognized_patterns),
            'action_history_count': len(self.action_history),
            'thresholds': self.thresholds,
            'active_alerts_count': len(self.active_alerts),
            'active_recommendations_count': len(self.active_recommendations),
            'active_predictions_count': len(self.active_predictions),
            'agent_start_time': self.agent_start_time,
            'last_update': self.last_update,
            'total_actions': self.total_actions,
            'prediction_accuracy': (
                self.successful_predictions / self.total_predictions
                if self.total_predictions > 0 else 0.0
            )
        }


class GridMonitorAgent:
    """
    Autonomous agent for proactive grid monitoring and management.
    Uses IEEE 738 calculations, pattern recognition, and AI-powered analysis.
    """

    def __init__(self, rating_calculator=None):
        """
        Initialize the autonomous grid monitoring agent

        Args:
            rating_calculator: RatingCalculator instance for IEEE 738 calculations
        """
        # Initialize Anthropic client for AI capabilities
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key or api_key == 'your_api_key_here':
            raise ValueError(
                "ANTHROPIC_API_KEY not set. Please add your API key to backend/.env file"
            )

        self.client = Anthropic(api_key=api_key)
        self.model = os.getenv('CLAUDE_MODEL', 'claude-3-5-haiku-20241022')
        self.max_tokens = int(os.getenv('MAX_TOKENS', 2048))
        self.temperature = float(os.getenv('TEMPERATURE', 0.5))

        # Rating calculator for IEEE 738 predictions
        self.rating_calculator = rating_calculator

        # Agent state
        self.state = AgentState()

        # Alert ID counter
        self._alert_counter = 0
        self._rec_counter = 0
        self._pred_counter = 0
        self._action_counter = 0

    def _generate_id(self, prefix: str) -> str:
        """Generate unique ID with prefix"""
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        if prefix == 'alert':
            self._alert_counter += 1
            return f"{prefix}_{timestamp}_{self._alert_counter}"
        elif prefix == 'rec':
            self._rec_counter += 1
            return f"{prefix}_{timestamp}_{self._rec_counter}"
        elif prefix == 'pred':
            self._pred_counter += 1
            return f"{prefix}_{timestamp}_{self._pred_counter}"
        else:
            self._action_counter += 1
            return f"{prefix}_{timestamp}_{self._action_counter}"

    def update_grid_history(self, current_data: Dict, weather: Dict):
        """
        Update historical grid data with current snapshot

        Args:
            current_data: Current grid ratings and line data
            weather: Current weather parameters
        """
        summary = current_data.get('summary', {})

        metrics = GridMetrics(
            timestamp=datetime.now().isoformat(),
            total_lines=summary.get('total_lines', 0),
            critical_count=summary.get('critical_count', 0),
            high_stress_count=summary.get('high_stress_count', 0),
            caution_count=summary.get('caution_count', 0),
            normal_count=summary.get('normal_count', 0),
            avg_loading=summary.get('avg_loading', 0.0),
            max_loading=summary.get('max_loading', 0.0),
            max_loading_line=summary.get('max_loading_line', 'N/A'),
            weather_temp=weather.get('Ta', weather.get('ambient_temp', 25)),
            weather_wind_speed=weather.get('WindVelocity', weather.get('wind_speed', 2.0)),
            weather_wind_angle=weather.get('WindAngleDeg', weather.get('wind_angle', 90)),
            weather_sun_time=weather.get('SunTime', weather.get('sun_time', 12))
        )

        self.state.grid_history.append(metrics)
        self.state.last_update = datetime.now().isoformat()

    def monitor_grid_state(self, current_data: Dict, weather: Dict) -> Dict:
        """
        Analyze current grid conditions and detect issues

        Args:
            current_data: Current grid ratings and line data
            weather: Current weather parameters

        Returns:
            Dictionary containing detected issues and recommendations
        """
        # Update historical data
        self.update_grid_history(current_data, weather)

        issues = []
        recommendations = []

        lines = current_data.get('lines', [])
        summary = current_data.get('summary', {})

        # Issue Detection

        # 1. Critical overloads
        critical_lines = [l for l in lines if l['stress_level'] == 'critical']
        if critical_lines:
            issues.append({
                'severity': 'emergency',
                'type': 'critical_overload',
                'description': f"{len(critical_lines)} line(s) critically overloaded (≥100% loading)",
                'affected_lines': [l['name'] for l in critical_lines],
                'details': critical_lines
            })
            recommendations.append({
                'priority': 1,
                'action': 'Immediate load shedding or line switching',
                'justification': 'Critical overloads can lead to line trips and cascading failures'
            })

        # 2. High stress conditions
        high_stress_lines = [l for l in lines if l['stress_level'] == 'high']
        if high_stress_lines:
            issues.append({
                'severity': 'critical',
                'type': 'high_stress',
                'description': f"{len(high_stress_lines)} line(s) under high stress (90-100% loading)",
                'affected_lines': [l['name'] for l in high_stress_lines],
                'details': high_stress_lines
            })
            recommendations.append({
                'priority': 2,
                'action': 'Prepare contingency plans and monitor closely',
                'justification': 'High stress lines are at risk of overload with minor changes'
            })

        # 3. Trending analysis (if we have history)
        if len(self.state.grid_history) >= 5:
            trend_issues = self._detect_trends()
            issues.extend(trend_issues)

        # 4. Weather sensitivity analysis
        hot_calm_conditions = (
            weather.get('Ta', weather.get('ambient_temp', 25)) > 35 and
            weather.get('WindVelocity', weather.get('wind_speed', 2.0)) < 1.5
        )

        if hot_calm_conditions:
            caution_lines = [l for l in lines if l['stress_level'] in ['caution', 'high', 'critical']]
            if caution_lines:
                issues.append({
                    'severity': 'warning',
                    'type': 'adverse_weather',
                    'description': 'Hot and calm weather conditions reducing line ratings',
                    'affected_lines': [l['name'] for l in caution_lines],
                    'details': {
                        'temperature': weather.get('Ta', 25),
                        'wind_speed': weather.get('WindVelocity', 2.0),
                        'impact': 'Reduced cooling capacity for transmission lines'
                    }
                })
                recommendations.append({
                    'priority': 2,
                    'action': 'Monitor weather forecast and prepare for potential rating reductions',
                    'justification': 'Ratings may decrease further if conditions worsen'
                })

        # 5. Pattern matching
        pattern_issues = self._match_patterns(current_data, weather)
        issues.extend(pattern_issues)

        return {
            'timestamp': datetime.now().isoformat(),
            'issues_detected': len(issues),
            'issues': issues,
            'recommendations': recommendations,
            'grid_status': self._calculate_grid_status(summary)
        }

    def _detect_trends(self) -> List[Dict]:
        """Detect concerning trends in historical data"""
        issues = []

        # Get recent history (last 10 snapshots)
        recent = list(self.state.grid_history)[-10:]

        if len(recent) < 5:
            return issues

        # Calculate loading trend
        loadings = [m.avg_loading for m in recent]
        times = list(range(len(loadings)))

        # Simple linear regression
        if len(loadings) >= 3:
            z = np.polyfit(times, loadings, 1)
            slope = z[0]

            # If loading is increasing rapidly
            if slope > self.state.thresholds['trend']['loading_increase_rate']:
                issues.append({
                    'severity': 'warning',
                    'type': 'increasing_trend',
                    'description': f'Average loading increasing at {slope:.2f}% per snapshot',
                    'affected_lines': ['system-wide'],
                    'details': {
                        'slope': slope,
                        'recent_loadings': loadings,
                        'projection': loadings[-1] + slope * 5  # Project 5 snapshots ahead
                    }
                })

        return issues

    def _match_patterns(self, current_data: Dict, weather: Dict) -> List[Dict]:
        """Match current conditions against recognized patterns"""
        issues = []

        for pattern in self.state.recognized_patterns:
            if pattern.confidence < self.state.thresholds['pattern_confidence']:
                continue

            # Check if current conditions match pattern triggers
            match_score = self._calculate_pattern_match(pattern, current_data, weather)

            if match_score > 0.8:
                # Pattern matched - predict likely outcome
                issues.append({
                    'severity': 'info',
                    'type': 'pattern_match',
                    'description': f'Conditions similar to known pattern: {pattern.pattern_type}',
                    'affected_lines': [],
                    'details': {
                        'pattern': pattern.pattern_type,
                        'confidence': pattern.confidence,
                        'match_score': match_score,
                        'expected_outcomes': pattern.observed_outcomes
                    }
                })

        return issues

    def _calculate_pattern_match(self, pattern: PatternData, current_data: Dict, weather: Dict) -> float:
        """Calculate how well current conditions match a pattern"""
        # Simplified matching - can be enhanced
        triggers = pattern.trigger_conditions

        matches = 0
        total = len(triggers)

        if total == 0:
            return 0.0

        summary = current_data.get('summary', {})

        # Check weather conditions
        if 'temp_range' in triggers:
            temp = weather.get('Ta', weather.get('ambient_temp', 25))
            if triggers['temp_range'][0] <= temp <= triggers['temp_range'][1]:
                matches += 1

        # Check loading levels
        if 'avg_loading_range' in triggers:
            avg_loading = summary.get('avg_loading', 0)
            if triggers['avg_loading_range'][0] <= avg_loading <= triggers['avg_loading_range'][1]:
                matches += 1

        return matches / total

    def _calculate_grid_status(self, summary: Dict) -> str:
        """Calculate overall grid status"""
        if summary.get('critical_count', 0) > 0:
            return 'EMERGENCY'
        elif summary.get('high_stress_count', 0) > 3:
            return 'CRITICAL'
        elif summary.get('high_stress_count', 0) > 0:
            return 'HIGH_STRESS'
        elif summary.get('caution_count', 0) > 5:
            return 'CAUTION'
        else:
            return 'NORMAL'

    def predict_future_states(self, weather_forecast: List[Dict]) -> Dict:
        """
        Calculate expected line ratings under forecasted weather conditions

        Args:
            weather_forecast: List of weather forecasts (each with Ta, WindVelocity, etc.)

        Returns:
            Predictive alerts and future state analysis
        """
        if not self.rating_calculator:
            return {
                'error': 'Rating calculator not initialized',
                'predictions': []
            }

        predictions = []
        alerts = []

        for idx, forecast in enumerate(weather_forecast):
            try:
                # Calculate future ratings using IEEE 738
                future_ratings = self.rating_calculator.calculate_all_line_ratings(forecast)

                forecast_time = datetime.now() + timedelta(hours=idx + 1)

                # Analyze predicted state
                summary = future_ratings.get('summary', {})

                prediction = Prediction(
                    prediction_id=self._generate_id('pred'),
                    timestamp=datetime.now().isoformat(),
                    forecast_time=forecast_time.isoformat(),
                    predicted_metrics={
                        'avg_loading': summary.get('avg_loading', 0),
                        'max_loading': summary.get('max_loading', 0),
                        'critical_count': summary.get('critical_count', 0),
                        'high_stress_count': summary.get('high_stress_count', 0),
                        'weather': forecast
                    },
                    confidence=0.85 - (idx * 0.05),  # Confidence decreases with time
                    risk_factors=self._identify_risk_factors(future_ratings, forecast),
                    preventive_actions=self._generate_preventive_actions(future_ratings)
                )

                predictions.append(prediction)

                # Generate alerts for predicted issues
                if summary.get('critical_count', 0) > 0:
                    alert = Alert(
                        alert_id=self._generate_id('alert'),
                        timestamp=datetime.now().isoformat(),
                        severity='critical',
                        title=f'Predicted overloads in {idx + 1} hour(s)',
                        description=f'{summary.get("critical_count")} lines predicted to overload',
                        affected_lines=[
                            l['name'] for l in future_ratings.get('lines', [])
                            if l.get('stress_level') == 'critical'
                        ],
                        recommended_actions=self._generate_preventive_actions(future_ratings),
                        confidence=prediction.confidence,
                        pattern_match=None
                    )
                    alerts.append(alert)

            except Exception as e:
                predictions.append({
                    'error': f'Failed to calculate forecast {idx + 1}: {str(e)}',
                    'forecast_time': (datetime.now() + timedelta(hours=idx + 1)).isoformat()
                })

        self.state.active_predictions = predictions
        self.state.total_predictions += len(predictions)

        return {
            'timestamp': datetime.now().isoformat(),
            'predictions': [p.model_dump() if isinstance(p, Prediction) else p for p in predictions],
            'alerts': [a.model_dump() for a in alerts],
            'forecast_horizon_hours': len(weather_forecast)
        }

    def _identify_risk_factors(self, future_ratings: Dict, weather: Dict) -> List[str]:
        """Identify risk factors in predicted state"""
        risks = []

        summary = future_ratings.get('summary', {})

        if summary.get('critical_count', 0) > 0:
            risks.append(f"{summary['critical_count']} lines predicted to overload")

        if weather.get('Ta', 25) > 40:
            risks.append("Extreme high temperature conditions")

        if weather.get('WindVelocity', 2.0) < 1.0:
            risks.append("Low wind speed reducing cooling capacity")

        if summary.get('avg_loading', 0) > 75:
            risks.append("High system-wide loading predicted")

        return risks

    def _generate_preventive_actions(self, future_ratings: Dict) -> List[str]:
        """Generate preventive actions for predicted issues"""
        actions = []

        summary = future_ratings.get('summary', {})
        lines = future_ratings.get('lines', [])

        if summary.get('critical_count', 0) > 0:
            critical_lines = [l['name'] for l in lines if l.get('stress_level') == 'critical']
            actions.append(f"Prepare to reduce loading on: {', '.join(critical_lines[:3])}")
            actions.append("Coordinate with generation dispatch for load redistribution")

        if summary.get('high_stress_count', 0) > 2:
            actions.append("Activate contingency operating procedures")
            actions.append("Increase monitoring frequency to 15-minute intervals")

        if len(actions) == 0:
            actions.append("Continue normal monitoring")

        return actions

    def generate_recommendations(self, issues: List[Dict]) -> Dict:
        """
        Create prioritized action items with impact analysis

        Args:
            issues: List of detected issues from monitor_grid_state

        Returns:
            Structured response with prioritized recommendations and justifications
        """
        recommendations = []

        # Use AI to generate intelligent recommendations
        try:
            # Build context
            context = {
                'issues': issues,
                'grid_history_count': len(self.state.grid_history),
                'active_patterns': len(self.state.recognized_patterns),
                'current_thresholds': self.state.thresholds
            }

            prompt = f"""As an autonomous grid monitoring agent, analyze these detected issues and generate prioritized recommendations:

DETECTED ISSUES:
{json.dumps(issues, indent=2)}

AGENT CONTEXT:
{json.dumps(context, indent=2)}

Generate 3-5 prioritized recommendations. For each recommendation provide:
1. Priority (1-5, 1 being most critical)
2. Title (concise description)
3. Detailed description
4. Justification (why this action is needed)
5. Expected impact (what will improve)
6. Actionable steps (specific actions to take)
7. Confidence level (0.0-1.0)

Format as JSON array of recommendations."""

            message = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                messages=[{"role": "user", "content": prompt}]
            )

            response_text = message.content[0].text

            # Try to parse AI response as JSON
            try:
                # Extract JSON from response (handle markdown code blocks)
                json_start = response_text.find('[')
                json_end = response_text.rfind(']') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = response_text[json_start:json_end]
                    ai_recs = json.loads(json_str)

                    # Convert to Recommendation objects
                    for rec_data in ai_recs:
                        rec = Recommendation(
                            rec_id=self._generate_id('rec'),
                            timestamp=datetime.now().isoformat(),
                            priority=rec_data.get('priority', 3),
                            title=rec_data.get('title', 'Recommendation'),
                            description=rec_data.get('description', ''),
                            justification=rec_data.get('justification', ''),
                            expected_impact=rec_data.get('expected_impact', {}),
                            confidence=rec_data.get('confidence', 0.7),
                            actionable_steps=rec_data.get('actionable_steps', [])
                        )
                        recommendations.append(rec)
                else:
                    # Fallback: use response as single recommendation
                    rec = Recommendation(
                        rec_id=self._generate_id('rec'),
                        timestamp=datetime.now().isoformat(),
                        priority=2,
                        title='AI Analysis',
                        description=response_text,
                        justification='Generated from autonomous analysis',
                        expected_impact={'type': 'general'},
                        confidence=0.7,
                        actionable_steps=['Review AI analysis']
                    )
                    recommendations.append(rec)

            except json.JSONDecodeError:
                # Fallback if JSON parsing fails
                rec = Recommendation(
                    rec_id=self._generate_id('rec'),
                    timestamp=datetime.now().isoformat(),
                    priority=2,
                    title='AI Analysis',
                    description=response_text,
                    justification='Generated from autonomous analysis',
                    expected_impact={'type': 'general'},
                    confidence=0.7,
                    actionable_steps=['Review AI analysis']
                )
                recommendations.append(rec)

        except Exception as e:
            # Fallback to rule-based recommendations
            recommendations = self._generate_rule_based_recommendations(issues)

        # Update state
        self.state.active_recommendations = recommendations
        self.state.total_actions += len(recommendations)

        # Sort by priority
        sorted_recs = sorted(recommendations, key=lambda r: r.priority)

        return {
            'timestamp': datetime.now().isoformat(),
            'recommendations_count': len(sorted_recs),
            'recommendations': [r.model_dump() for r in sorted_recs]
        }

    def _generate_rule_based_recommendations(self, issues: List[Dict]) -> List[Recommendation]:
        """Fallback rule-based recommendation generation"""
        recommendations = []

        for issue in issues:
            priority = {
                'emergency': 1,
                'critical': 2,
                'warning': 3,
                'info': 4
            }.get(issue.get('severity', 'info'), 5)

            rec = Recommendation(
                rec_id=self._generate_id('rec'),
                timestamp=datetime.now().isoformat(),
                priority=priority,
                title=f"Address {issue.get('type', 'issue')}",
                description=issue.get('description', 'Issue detected'),
                justification=f"Severity: {issue.get('severity', 'unknown')}",
                expected_impact={
                    'affected_lines': issue.get('affected_lines', []),
                    'issue_type': issue.get('type', 'unknown')
                },
                confidence=0.8,
                actionable_steps=[
                    f"Review affected lines: {', '.join(issue.get('affected_lines', [])[:3])}",
                    "Take appropriate corrective action based on severity"
                ]
            )
            recommendations.append(rec)

        return recommendations

    def learn_from_outcomes(self, action: ActionRecord, result: Dict):
        """
        Update pattern recognition and adjust thresholds based on outcomes

        Args:
            action: The action that was taken
            result: The outcome/result of the action
        """
        # Record the action with outcome
        action.grid_state_after = result.get('grid_state_after', {})
        action.outcome = result.get('outcome', 'pending')
        action.impact_score = result.get('impact_score', 0.0)

        self.state.action_history.append(action)

        # Update pattern recognition if this was a successful action
        if action.outcome == 'successful' and action.impact_score > 0.5:
            # Extract pattern from successful action
            pattern = PatternData(
                pattern_type=action.action_type,
                trigger_conditions=self._extract_conditions(action.grid_state_before),
                observed_outcomes=[{
                    'action': action.description,
                    'impact': action.impact_score,
                    'timestamp': action.timestamp
                }],
                confidence=0.6,  # Initial confidence
                occurrence_count=1,
                last_seen=action.timestamp,
                avg_severity=action.impact_score
            )

            # Check if similar pattern exists
            similar_pattern = self._find_similar_pattern(pattern)
            if similar_pattern:
                # Update existing pattern
                similar_pattern.occurrence_count += 1
                similar_pattern.confidence = min(0.95, similar_pattern.confidence + 0.05)
                similar_pattern.last_seen = action.timestamp
                similar_pattern.observed_outcomes.append(pattern.observed_outcomes[0])
                # Update average severity
                similar_pattern.avg_severity = (
                    (similar_pattern.avg_severity * (similar_pattern.occurrence_count - 1) +
                     action.impact_score) / similar_pattern.occurrence_count
                )
            else:
                # Add new pattern
                self.state.recognized_patterns.append(pattern)

        # Adjust thresholds if needed (simple learning mechanism)
        if action.outcome == 'failed':
            # If action failed, maybe our thresholds are too loose
            if action.action_type == 'alert':
                # Slightly lower alert thresholds to be more proactive
                self.state.thresholds['loading']['caution'] = max(
                    50.0,
                    self.state.thresholds['loading']['caution'] - 1.0
                )

        # Track prediction accuracy
        if action.action_type == 'prediction':
            if action.outcome == 'successful':
                self.state.successful_predictions += 1

    def _extract_conditions(self, grid_state: Dict) -> Dict:
        """Extract key conditions from grid state for pattern matching"""
        return {
            'avg_loading_range': [
                max(0, grid_state.get('avg_loading', 0) - 10),
                grid_state.get('avg_loading', 0) + 10
            ],
            'temp_range': [
                max(-50, grid_state.get('weather_temp', 25) - 5),
                min(60, grid_state.get('weather_temp', 25) + 5)
            ]
        }

    def _find_similar_pattern(self, pattern: PatternData) -> Optional[PatternData]:
        """Find similar existing pattern"""
        for existing in self.state.recognized_patterns:
            if existing.pattern_type == pattern.pattern_type:
                # Simple similarity check
                return existing
        return None

    def get_agent_status(self) -> Dict:
        """Get current agent state and status"""
        return {
            'agent_status': 'active',
            'uptime_seconds': (
                datetime.now() - datetime.fromisoformat(self.state.agent_start_time)
            ).total_seconds(),
            'state': self.state.to_dict(),
            'active_alerts': [a.model_dump() for a in self.state.active_alerts],
            'active_recommendations': [r.model_dump() for r in self.state.active_recommendations],
            'active_predictions': [
                p.model_dump() if isinstance(p, Prediction) else p
                for p in self.state.active_predictions
            ],
            'learning_metrics': {
                'patterns_learned': len(self.state.recognized_patterns),
                'actions_recorded': len(self.state.action_history),
                'prediction_accuracy': (
                    self.state.successful_predictions / self.state.total_predictions
                    if self.state.total_predictions > 0 else 0.0
                )
            }
        }
